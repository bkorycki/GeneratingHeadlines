{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "\n",
    "from util import load_model, get_tokenizer\n",
    "from data_util import NewsDataset, get_data\n",
    "from generate_util import sample_seq, beam_search\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"med_desc_target\"\n",
    "CHECKPOINT = 10\n",
    "\n",
    "with open(f\"./config/{EXPERIMENT_NAME}.yaml\", 'r') as file:\n",
    "\tconfig = yaml.safe_load(file)\n",
    "\n",
    "MODEL_PATH = f'./output/{EXPERIMENT_NAME}/models/checkpoint_epoch{CHECKPOINT}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = config[\"RANDOM_SEED\"]\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.random.manual_seed(RANDOM_SEED)\n",
    "import random\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 articles loaded.\n",
      "6461 samples after cleaning\n",
      "646\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(config[\"GPT_SIZE\"])\n",
    "\n",
    "df = get_data(tokenizer)\n",
    "df_train, df_test = train_test_split(df, train_size=int(config[\"TRAIN_SPLIT\"]*len(df)), random_state=RANDOM_SEED)\n",
    "df_test, df_val = train_test_split(df_test, train_size=int(config[\"TEST_SPLIT\"]*len(df)), random_state=RANDOM_SEED)\n",
    "\n",
    "test_dataset = NewsDataset(df_test, tokenizer, config[\"TARGET_TYPE\"])\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(data, tokenizer, model, num=1, length=20, temperature=1, top_k=0, top_p=0.5, device=torch.device('cuda')):\n",
    "    # Set seed in between subsequent calls for reproducibility\n",
    "    torch.manual_seed(RANDOM_SEED) \n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    for i in range(num):\n",
    "        print(\"*\"*50)\n",
    "        sample = data[i]\n",
    "        idx = sample['sep_pos']\n",
    "        description = sample['token_ids'][:idx].tolist()\n",
    "        title = sample['token_ids'][idx+1:][:100].tolist()\n",
    "\n",
    "        generated_tokens = sample_seq(model, description, length, device, temperature, top_k, top_p)\n",
    "        generated_tokens = generated_tokens[0, len(description):].tolist()\n",
    "        generated_title = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "  \n",
    "        print('Description:\\n', tokenizer.decode(description, skip_special_tokens=True))\n",
    "        print(\"\\nGENERATED title:\\n\", generated_title)\n",
    "        print('TRUE title:\\n', tokenizer.decode(title,skip_special_tokens=True),\"   \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(MODEL_PATH, tokenizer, config[\"GPT_SIZE\"])\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Description:\n",
      " Healthcare of Ontario Pension Plan Trust Fund Decreases Stake in Target Co. (NYSE:TGT)\n",
      "\n",
      "GENERATED title:\n",
      "  Healthcare of Ontario Pension Plan Trust Fund decreased its stake in Target Co. (NYSE:TGT - Get Rating) by 11.3% during the third quarter, HoldingsChannel.com reports. The institutional investor owned 0,078,840 shares of the industrial products company's stock after selling 1,093,581 shares during the quarter. Healthcare of Ontario Pension Plan Trust Fund's holdings in Target [...]Welcome to the Wiki for the Foothills Christian School. Please read the rules before\n",
      "TRUE title:\n",
      " Healthcare of Ontario Pension Plan Trust Fund cut its holdings in Target Co. (NYSE:TGT - Get Rating) by 88.9% during the third quarter, according to the company in its most recent Form 13F filing with the Securities and Exchange Commission (SEC). The institutional investor owned 3,529 shares of the retailer's stock after selling 28,196 shares [...]    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate_beam_sample(test_dataset, tokenizer, model, num=1, device=device)\n",
    "\n",
    "generate_sample(test_dataset, tokenizer, model, num=1, device=device, length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_beam_sample(data, tokenizer, model, num=1, length=20, beam_size=3, device=torch.device('cuda')):\n",
    "    for i in range(num):\n",
    "        sample = data[i]\n",
    "        idx = sample['sep_pos']\n",
    "        context = sample['token_ids'][:idx].tolist()\n",
    "        summary = sample['token_ids'][idx+1:][:100].tolist()\n",
    "        scores, sequences = beam_search(model, context, length, beam_size, device)\n",
    "        print('description', end='\\n\\n')\n",
    "        print(tokenizer.decode(context[:-1]), end='\\n\\n')\n",
    "        # print('actual_summary', end='\\n\\n')\n",
    "        # print(tokenizer.decode(summary), end='\\n\\n')\n",
    "        for i in range(len(sequences)):\n",
    "            text = tokenizer.convert_ids_to_tokens(sequences[i],skip_special_tokens=True)\n",
    "            text = tokenizer.convert_tokens_to_string(text)  \n",
    "            print(\"generated_summary-{} and Score is {}.\".format(i+1, scores[i]), end='\\n\\n')\n",
    "            print(text, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = test_dataset[0]\n",
    "# idx = sample['sep_pos']\n",
    "# description = sample['token_ids'][:idx].unsqueeze(0)\n",
    "# title = sample['token_ids'][idx+1:][:100].tolist()\n",
    "\n",
    "# sample_output = model.generate(\n",
    "#     description, \n",
    "#     do_sample=True, \n",
    "#     max_length=95, \n",
    "#     top_k=0\n",
    "# )\n",
    "# tokens = sample_output[0, len(description[0]):]\n",
    "\n",
    "# print(\"Output:\\n\" + 100 * '-')\n",
    "# print(tokenizer.decode(tokens, skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
